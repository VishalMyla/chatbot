{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-community in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-pinecone in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.2.5)\n",
      "Requirement already satisfied: pinecone-client==2.2.4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (2.2.4)\n",
      "Requirement already satisfied: tqdm in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (6.0.2)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (0.7.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (4.13.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone-client==2.2.4) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-community) (3.10.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-pinecone) (0.3.17)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (4.51.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: pytest<9,>=7 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.5)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
      "Requirement already satisfied: syrupy<5,>=4 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.1)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: annotated-types>=0.6.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.10)\n",
      "Requirement already satisfied: greenlet>=1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: iniconfig in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
      "    return command.main(cmd_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 236, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 188, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    upgrade_prompt = _self_version_check_logic(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py\", line 199, in _self_version_check_logic\n",
      "    remote_version_str = get_remote_version()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/self_outdated_check.py\", line 183, in _get_current_remote_pip_version\n",
      "    best_candidate = finder.find_best_candidate(\"pip\").best_candidate\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/package_finder.py\", line 890, in find_best_candidate\n",
      "    candidates = self.find_all_candidates(project_name)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/package_finder.py\", line 831, in find_all_candidates\n",
      "    page_candidates = list(page_candidates_it)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/sources.py\", line 194, in page_candidates\n",
      "    yield from self._candidates_from_page(self._link)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/package_finder.py\", line 791, in process_project_url\n",
      "    index_response = self._link_collector.fetch_response(project_url)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/collector.py\", line 461, in fetch_response\n",
      "    return _get_index_content(location, session=self.session)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/collector.py\", line 364, in _get_index_content\n",
      "    resp = _get_simple_response(url, session=session)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/index/collector.py\", line 135, in _get_simple_response\n",
      "    resp = session.get(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_internal/network/session.py\", line 520, in request\n",
      "    return super().request(method, url, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py\", line 725, in send\n",
      "    history = [resp for resp in gen]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py\", line 266, in resolve_redirects\n",
      "    resp = self.send(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py\", line 363, in connect\n",
      "    self.sock = conn = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/pip/_vendor/urllib3/util/connection.py\", line 72, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/socket.py\", line 963, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Markdown Documents to MiniLM QnA System\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "# Install necessary packages - make sure the Pinecone version is compatible\n",
    "!pip install langchain langchain-community langchain-pinecone pinecone-client==2.2.4 tqdm python-dotenv sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFaceTextGenInference\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading markdown files from ./data...\n",
      "Found 1262 markdown files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1262/1262 [00:00<00:00, 4913.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1262 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Data Loading\n",
    "\n",
    "# Load markdown files from the 'data' folder\n",
    "def load_markdown_files(data_dir=\"./data\"):\n",
    "    \"\"\"\n",
    "    Load all markdown files from the specified directory\n",
    "    \"\"\"\n",
    "    print(f\"Loading markdown files from {data_dir}...\")\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Directory {data_dir} not found!\")\n",
    "        return []\n",
    "    \n",
    "    # Get all markdown files\n",
    "    md_files = glob.glob(os.path.join(data_dir, \"**/*.md\"), recursive=True)\n",
    "    print(f\"Found {len(md_files)} markdown files\")\n",
    "    \n",
    "    # Load documents\n",
    "    documents = []\n",
    "    for file_path in tqdm(md_files):\n",
    "        try:\n",
    "            loader = TextLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents\n",
    "\n",
    "# Load all markdown documents\n",
    "documents = load_markdown_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking documents...\n",
      "Created 20624 chunks\n"
     ]
    }
   ],
   "source": [
    "## Text Chunking\n",
    "\n",
    "# Split documents into chunks\n",
    "def chunk_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into chunks with specified size and overlap\n",
    "    \"\"\"\n",
    "    print(\"Chunking documents...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "# Create chunks from documents\n",
    "chunks = chunk_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking documents...\n",
      "Created 20624 chunks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Text Chunking\n",
    "\n",
    "# Split documents into chunks\n",
    "def chunk_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into chunks with specified size and overlap\n",
    "    \"\"\"\n",
    "    print(\"Chunking documents...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "# Create chunks from documents\n",
    "chunks = chunk_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding model...\n"
     ]
    }
   ],
   "source": [
    "## Embedding Generation\n",
    "\n",
    "# Initialize embedding model\n",
    "def initialize_embeddings():\n",
    "    \"\"\"\n",
    "    Initialize the embedding model\n",
    "    \"\"\"\n",
    "    print(\"Initializing embedding model...\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"all-MiniLM-L6-v2\",  # A good lightweight model for embeddings\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = initialize_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "## Pinecone Setup and Vector Storage\n",
    "\n",
    "# Initialize Pinecone and create index\n",
    "def setup_pinecone():\n",
    "    \"\"\"\n",
    "    Initialize Pinecone and create vector store\n",
    "    \"\"\"\n",
    "    print(\"Setting up Pinecone...\")\n",
    "    \n",
    "    # Get API key and environment from .env file\n",
    "    api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "    environment = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "    index_name = os.getenv(\"PINECONE_INDEX_NAME\", \"markdown-docs\")\n",
    "    \n",
    "    if not api_key or not environment:\n",
    "        raise ValueError(\"Pinecone API key and environment must be set in .env file\")\n",
    "    \n",
    "    # Initialize Pinecone (using the older API style)\n",
    "    #pinecone.init(api_key=api_key, environment=environment)\n",
    "    pc = Pinecone(api_key=api_key)\n",
    "    \n",
    "    if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "        print(f\"Creating new Pinecone index: {index_name}\")\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,  # 384 for all-MiniLM-L6-v2\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",        # or \"gcp\" depending on your plan\n",
    "                region=environment  # example: \"us-west-2\"\n",
    "            )\n",
    "        )\n",
    "        print(f\"Successfully created index: {index_name}\")\n",
    "    else:\n",
    "        print(f\"Using existing index: {index_name}\")\n",
    "\n",
    "    return index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pinecone...\n",
      "Creating new Pinecone index: etq1\n",
      "Successfully created index: etq1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup Pinecone\n",
    "index_name = setup_pinecone()\n",
    "\n",
    "\n",
    "## Store Document Chunks in Pinecone\n",
    "\n",
    "# Create vector store and add documents\n",
    "def store_embeddings(chunks, embeddings, index_name):\n",
    "    \"\"\"\n",
    "    Store document chunks in Pinecone vector store\n",
    "    \"\"\"\n",
    "    print(\"Creating vector store and storing embeddings...\")\n",
    "    \n",
    "    try:\n",
    "        # Create vector store with older Pinecone API style\n",
    "        vector_store = PineconeVectorStore.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            index_name=index_name\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully stored {len(chunks)} document chunks in Pinecone\")\n",
    "        return vector_store\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error storing embeddings: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store and storing embeddings...\n",
      "Successfully stored 20624 document chunks in Pinecone\n",
      "Initializing MiniLM model for generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_231939/2244647906.py:45: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  model = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Store embeddings in Pinecone\n",
    "vector_store = store_embeddings(chunks, embeddings, index_name)\n",
    "\n",
    "## Initialize MiniLM Model for Generation\n",
    "\n",
    "# Initialize MiniLM model for Q&A\n",
    "def initialize_minilm_model(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", inference_server_url=None):\n",
    "    \"\"\"\n",
    "    Initialize the MiniLM model for question answering\n",
    "    \"\"\"\n",
    "    print(\"Initializing MiniLM model for generation...\")\n",
    "    \n",
    "    # If using a hosted inference API, we can use HuggingFaceTextGenInference\n",
    "    if inference_server_url:\n",
    "        model = HuggingFaceTextGenInference(\n",
    "            inference_server_url=inference_server_url,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.1,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    else:\n",
    "        # For local usage, we can use HuggingFacePipeline\n",
    "        from langchain_community.llms import HuggingFacePipeline\n",
    "        from transformers import AutoTokenizer, pipeline\n",
    "        \n",
    "        # Import required modules\n",
    "        try:\n",
    "            from transformers import AutoModelForSeq2SeqLM\n",
    "            \n",
    "            # First try loading as a seq2seq model\n",
    "            try:\n",
    "                model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "                \n",
    "                # Create a pipeline for text generation\n",
    "                pipe = pipeline(\n",
    "                    \"text2text-generation\",\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_length=512,\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                \n",
    "                # Create the LangChain wrapper\n",
    "                model = HuggingFacePipeline(pipeline=pipe)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Could not load as seq2seq model: {e}\")\n",
    "                # Fallback to using a smaller T5 model which is better for QA\n",
    "                model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "                \n",
    "                pipe = pipeline(\n",
    "                    \"text2text-generation\",\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_length=512\n",
    "                )\n",
    "                \n",
    "                model = HuggingFacePipeline(pipeline=pipe)\n",
    "                \n",
    "        except ImportError as e:\n",
    "            print(f\"Error importing transformers components: {e}\")\n",
    "            print(\"Using a simple model interface for demonstration\")\n",
    "            \n",
    "            # Create a simple model interface\n",
    "            from langchain.llms.base import LLM\n",
    "            \n",
    "            class SimpleResponseModel(LLM):\n",
    "                def _call(self, prompt, stop=None):\n",
    "                    # This is a simple model that just returns a fixed response based on the context\n",
    "                    if \"Context:\" in prompt and \"Question:\" in prompt:\n",
    "                        return \"Based on the provided context, here's what I found in your documents.\"\n",
    "                    return \"I don't have enough context to answer this question.\"\n",
    "                \n",
    "                @property\n",
    "                def _identifying_params(self):\n",
    "                    return {\"name\": \"SimpleResponseModel\"}\n",
    "                \n",
    "                @property\n",
    "                def _llm_type(self):\n",
    "                    return \"simple\"\n",
    "            \n",
    "            model = SimpleResponseModel()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "inference_server_url = os.getenv(\"INFERENCE_SERVER_URL\", None)  # Optional: URL to hosted inference API\n",
    "model = initialize_minilm_model(inference_server_url=inference_server_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating QA chain...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Create QA Chain\n",
    "\n",
    "# Create QA chain with retrieved context\n",
    "def create_qa_chain(model, vector_store):\n",
    "    \"\"\"\n",
    "    Create a QA chain with the model and vector store\n",
    "    \"\"\"\n",
    "    print(\"Creating QA chain...\")\n",
    "    \n",
    "    # Create a prompt template that includes context\n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful AI assistant. Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer or if the answer is not in the given context, say \"I don't have enough information to answer this question.\"\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # Create the chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=model,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "# Create the QA chain\n",
    "qa_chain = create_qa_chain(model, vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: xample: ABC Group’s Loyalty Program\n",
      "\n",
      "Consider a company ABC Group that want to manage a common loyalty program across its various brands, such as:\n",
      "\n",
      "- GroceryMart:A grocery and essentials chain.\n",
      "\n",
      "- TechStore:A store specializing in gadgets and electronics.\n",
      "\n",
      "- FashionStores:A clothing and accessories brand.\n",
      "\n",
      "They can use the Standard Organisation framework to meet their requirements.\n",
      "what are benefits? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangnik/.pyenv/versions/3.12.2/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Unified Point System: Customers earn points on purchases made at any brand under ABC Group. - Flexible Redemption: Points can be redeemed across all participating brands.\n",
      "\n",
      "Sources:\n",
      "Source 1:\n",
      "  Content: #### Example: ABC Jewellers Loyalty Program\n",
      "\n",
      "- Single loyalty program across all outlets\n",
      "\n",
      "- Centralised customer database\n",
      "\n",
      "- Unified points system\n",
      "\n",
      "- ...\n",
      "  Source: ./data/ADMIN_CONTROLS_Organization.md\n",
      "\n",
      "Source 2:\n",
      "  Content: Benefits:\n",
      "\n",
      "- Unified Point System: Customers earn points on purchases made at any brand under ABC Group.\n",
      "\n",
      "- Flexible Redemption: Points can be redeeme...\n",
      "  Source: ./data/ADMIN_CONTROLS_Organization.md\n",
      "\n",
      "Source 3:\n",
      "  Content: - Corporate Loyalty Programs: Employees making transactions and rewards are awarded and redeemed at a company level.\n",
      "\n",
      "### About User Group Loyalty\n",
      "\n",
      "Gr...\n",
      "  Source: ./data/Announcements_April-May-June_2021.md\n",
      "\n",
      "Source 4:\n",
      "  Content: Currently, the usability of Loyalty+ for any business or a brand is limited to benefit its end customers. The current addition facilitates orgs to cre...\n",
      "  Source: ./data/Announcements_April-May-June_2021.md\n",
      "\n",
      "Source 5:\n",
      "  Content: | Affiliate Marketing Programs | The affiliate enrolled in the program can make customers buy products. With a product purchased by the customer, the ...\n",
      "  Source: ./data/Loyalty+_User_Group_loyalty.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Query Interface\n",
    "\n",
    "# Function to query the system\n",
    "def query_documents(qa_chain, query):\n",
    "    \"\"\"\n",
    "    Query the QA system with a question\n",
    "    \"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "    result = qa_chain({\"query\": query})\n",
    "    \n",
    "    answer = result[\"result\"]\n",
    "    sources = result[\"source_documents\"]\n",
    "    \n",
    "    print(\"\\nAnswer:\")\n",
    "    print(answer)\n",
    "    \n",
    "    print(\"\\nSources:\")\n",
    "    for i, doc in enumerate(sources):\n",
    "        print(f\"Source {i+1}:\")\n",
    "        print(f\"  Content: {doc.page_content[:150]}...\")\n",
    "        print(f\"  Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print()\n",
    "    \n",
    "    return answer, sources\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"xample: ABC Group’s Loyalty Program\n",
    "\n",
    "Consider a company ABC Group that want to manage a common loyalty program across its various brands, such as:\n",
    "\n",
    "- GroceryMart:A grocery and essentials chain.\n",
    "\n",
    "- TechStore:A store specializing in gadgets and electronics.\n",
    "\n",
    "- FashionStores:A clothing and accessories brand.\n",
    "\n",
    "They can use the Standard Organisation framework to meet their requirements.\n",
    "what are benefits? \"\"\"\n",
    "answer, sources = query_documents(qa_chain, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
